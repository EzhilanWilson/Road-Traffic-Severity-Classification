{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dabl\n",
    "import plotly.subplots\n",
    "import pandas               as pd\n",
    "import matplotlib.pyplot    as plt\n",
    "import matplotlib           as mpl\n",
    "import numpy                as np\n",
    "import seaborn              as sns\n",
    "import kaleido              as kaleido\n",
    "import missingno            as msno\n",
    "import xgboost              as xgb\n",
    "import shap                 as shap\n",
    "import plotly               as py\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io            as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = \"browser\"\n",
    "plotly.offline.init_notebook_mode()\n",
    "pio.renderers.default = 'png'\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from   mpl_toolkits.mplot3d    import Axes3D\n",
    "from   sklearn.model_selection import KFold\n",
    "from   sklearn.model_selection import GridSearchCV\n",
    "from   xgboost                 import XGBClassifier\n",
    "from   sklearn.model_selection import train_test_split\n",
    "from   sklearn.ensemble        import RandomForestClassifier\n",
    "from   sklearn.ensemble        import ExtraTreesClassifier\n",
    "from   imblearn.over_sampling  import SMOTE\n",
    "from   collections             import Counter\n",
    "from   sklearn.metrics         import accuracy_score\n",
    "from   sklearn.metrics         import precision_score\n",
    "from   sklearn.metrics         import recall_score\n",
    "from   sklearn.metrics         import f1_score\n",
    "from   sklearn.metrics         import confusion_matrix\n",
    "from   sklearn.metrics         import classification_report\n",
    "from   sklearn                 import preprocessing\n",
    "from   sklearn.preprocessing   import LabelEncoder\n",
    "from   IPython.display         import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rta    = pd.read_csv(dabl.datasets.data_path(r'E:\\Road-Traffic-Severity-Classification\\DATASET\\RTA Dataset.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis [ EDA ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option ('display.max_columns', None)\n",
    "pd.set_option ('display.max_rows', None)\n",
    "print (\"The Total no. of Features and Instances are\",  rta.shape)\n",
    "print (\"Taking a Quick Glance into how my data looks\",  rta.head)\n",
    "rta['Time'] = pd.to_datetime(rta['Time'])\n",
    "rta_clean   = dabl.clean(rta,   verbose=0)\n",
    "types       = dabl.detect_types(rta_clean)\n",
    "print (\"Quick Marker for my missing values & other dirty columns\", types)\n",
    "print (\"Quick analysis for describing main features of numericals in my data\",  rta.describe())\n",
    "print (\"\\n\", rta.info())\n",
    "print (\"Quick analysis for describing main features of categories in my data\",  rta.describe(include='object'))\n",
    "rta.hist(figsize=(8,8), xrot=45)\n",
    "plt.show()\n",
    "\n",
    "for col in rta.select_dtypes(include='object'):\n",
    "    if rta[col].nunique() <= 22:\n",
    "        sns.countplot(y=col, data=rta)\n",
    "        plt.show()\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "y    = label_encoder.fit_transform(rta['Accident_severity'])\n",
    "for col in rta.select_dtypes(include='object'):\n",
    "    if rta[col].nunique() <=4:\n",
    "        display(pd.crosstab(y, rta[col], normalize='index'))\n",
    "\n",
    "for col in rta.select_dtypes(include='object'):\n",
    "    if rta[col].nunique() <= 4:\n",
    "        g = sns.catplot(x = col, kind='count', col = 'Accident_severity', data=rta, sharey=False)\n",
    "        g.set_xticklabels(rotation=60)\n",
    "        plt.show()\n",
    "\n",
    "corr = rta.corr()\n",
    "print (\"Looking into Correlation Matrix\", corr)\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(corr, cmap='RdBu_r', annot=True, vmax=1, vmin=-1)\n",
    "plt.show()\n",
    "\n",
    "sns.violinplot(x=\"Number_of_casualties\", y=\"Vehicle_movement\", data=rta)\n",
    "plt.show()\n",
    "sns.violinplot(x=\"Number_of_casualties\", y=\"Type_of_collision\", data=rta, color=\"Yellow\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DETECTING THE MISSING VALUES & VISUAL MAPPING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(rta):\n",
    "    mis_val = rta.isnull().sum()\n",
    "    print(\"\\nThe total number of missing values are \", mis_val)\n",
    "    mis_val_percent = 100 * rta.isnull().sum() / len(rta)\n",
    "    print(\"\\nThe percentage of missing values are \", mis_val_percent)\n",
    "    mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "    print(\"\\nTable of total missing values and its percentages\", mis_val_table)\n",
    "    mis_val_table_ren_columns = mis_val_table.rename(\n",
    "    columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "    mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "    print(\"The master dataframe for Road Traffic Accidents has \" + str(rta.shape[1]) + \" columns.\\n\"\n",
    "          \"There are \" + str(mis_val_table_ren_columns.shape[0]) + \" columns that have missing values.\")\n",
    "    return mis_val_table_ren_columns\n",
    "missing_values_table(rta)\n",
    "\n",
    "msno.bar(rta)                                     #Identifying amount of data missing\n",
    "plt.show()\n",
    "msno.matrix(rta)                                  #Plotting patterns of data missing\n",
    "plt.show()\n",
    "msno.matrix(rta.sample(100))                      #Plotting 1st 100 rows (sub-strata)\n",
    "plt.show()\n",
    "sorted_wos = rta.sort_values('Work_of_casuality') #Identifying correlation of my missing datapoints\n",
    "msno.matrix(sorted_wos)\n",
    "plt.show()\n",
    "sorted_syv = rta.sort_values('Service_year_of_vehicle')\n",
    "msno.matrix(sorted_syv)\n",
    "plt.show()\n",
    "msno.heatmap(rta)\n",
    "plt.show()\n",
    "msno.dendrogram(rta)                              #Using Dendogram to figure more patterns\n",
    "plt.show()\n",
    "                                                  #Dropping columns with high level of imbalance\n",
    "rta.drop(columns= ['Defect_of_vehicle', 'Vehicle_driver_relation', 'Work_of_casuality', 'Fitness_of_casuality',], inplace=True)\n",
    "impute_cols = [x for x in rta.isna().sum()[rta.isna().sum()!=0].index.tolist()]\n",
    "for feat in impute_cols:\n",
    "    mode = rta[feat].mode()[0]\n",
    "    rta[feat].fillna(mode, inplace=True)\n",
    "print(rta.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FEATURE ENGINEERING & ENCODING RTA FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ordinal_encoder(rta, feats):\n",
    "    for feat in feats:\n",
    "        feat_val  = list (1+np.arange(rta[feat].nunique()))\n",
    "        feat_key  = list (rta[feat].sort_values().unique())\n",
    "        feat_dict = dict (zip(feat_key, feat_val))\n",
    "        rta[feat] = rta[feat].map(feat_dict)\n",
    "    return rta                                    #Visualizing the frame after Encoding\n",
    "rta = ordinal_encoder(rta, rta.drop(['Accident_severity'], axis=1).columns)\n",
    "print (\"The shape of my RTA data after Ordinal Encoding\", rta.head())\n",
    "for col in rta.drop('Accident_severity', axis=1):\n",
    "    g = sns.FacetGrid(rta, col= 'Accident_severity', aspect= 1.2, sharey= False)\n",
    "    g.map(sns.countplot, col, palette= 'Dark2')\n",
    "    plt.show()\n",
    "plt.figure(figsize=(22, 17))                      #Plotting correlation map    \n",
    "sns.set(font_scale= 0.8)\n",
    "sns.heatmap(rta.corr(), annot= True, cmap= plt.cm.get_cmap(\"CMRmap_r\"))\n",
    "plt.show()\n",
    "                                                  #Splitting RTA Data\n",
    "X = rta.drop('Accident_severity', axis= 1)\n",
    "Y = rta['Accident_severity']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size= 0.3, random_state= 42)\n",
    "print (\"Quick view to train and test dataframes\\n\", X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
    "le      = LabelEncoder()\n",
    "Y_train = le.fit_transform(Y_train)\n",
    "counter = Counter(Y_train)\n",
    "print (\"---------------------------------------------------------\")\n",
    "for k,v in counter.items():\n",
    "    per = 100*v/len(Y_train)\n",
    "    print (f\"Class= {k}, n= {v}, ({per: .2f}%)\")\n",
    "oversample = SMOTE()\n",
    "X_train, Y_train = oversample.fit_resample(X_train, Y_train)\n",
    "counter = Counter(Y_train)\n",
    "print (\"---------------------------------------------------------\")\n",
    "for k,v in counter.items():\n",
    "    per = 100*v/len(Y_train)\n",
    "    print (f\"Class= {k}, n= {v}, ({per: .2f}%)\")\n",
    "print (\"---------------------------------------------------------\")\n",
    "print (\"The shape of up|over sampled RTA Dataset: \", X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BASELINE MODELING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = le.fit_transform(Y_test)\n",
    "def modelling(X_train, Y_train, X_test, Y_test, **kwargs):\n",
    "    scores = {}\n",
    "    models = []\n",
    "    if  'xgb' in kwargs.keys() and kwargs['xgb']:\n",
    "        xgb     = XGBClassifier()\n",
    "        xgb.fit(X_train._get_numeric_data(), np.ravel(Y_train, order= 'C'))\n",
    "        global Y_pred\n",
    "        Y_pred         = xgb.predict(X_test._get_numeric_data())\n",
    "        scores['xgb']  = [accuracy_score(Y_test, Y_pred)]\n",
    "    if 'rf'  in kwargs.keys() and kwargs['rf']:\n",
    "        rf = RandomForestClassifier(n_estimators= 200)\n",
    "        rf.fit(X_train, Y_train)\n",
    "        Y_pred = rf.predict(X_test)\n",
    "        scores['rf'] = [accuracy_score(Y_test, Y_pred)]\n",
    "        models.append(rf)\n",
    "    if 'extree'  in kwargs.keys() and kwargs['extree']:\n",
    "        extree = ExtraTreesClassifier()\n",
    "        extree.fit(X_train, Y_train)\n",
    "        Y_pred = extree.predict(X_test)\n",
    "        scores['extree'] = [accuracy_score(Y_test, Y_pred)]\n",
    "        models.append(extree)\n",
    "    return scores\n",
    "print (\"My Baseline Model Output: \\n\")\n",
    "print (modelling(X_train, Y_train, X_test, Y_test, xgb= True, rf= True, extree= True))\n",
    "                                                  #Model Performance and Show Metrics\n",
    "def model_performance(model, Y_test, Y_hat):\n",
    "    conf_matrix = confusion_matrix(Y_test, Y_hat)\n",
    "    trace1 = go.Heatmap(z= conf_matrix, x= [\"0 (pred)\", \"1 (pred)\", \"2 (pred)\"],\n",
    "                        y= [\"0 (true)\", \"1 (true)\", \"2 (true)\"], xgap= 2, ygap= 2,\n",
    "                        colorscale= 'viridis', showscale= False)\n",
    "    Accuracy     = accuracy_score  (Y_test, Y_hat)\n",
    "    Precision    = precision_score (Y_test, Y_pred, average= 'weighted')\n",
    "    Recall       = recall_score    (Y_test, Y_pred, average= 'weighted')\n",
    "    F1_score     = f1_score        (Y_test, Y_pred, average= 'weighted')\n",
    "    show_metrics = pd.DataFrame (data= [[Accuracy, Precision, Recall, F1_score]])\n",
    "    show_metrics = show_metrics.T\n",
    "\n",
    "    colors       = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n",
    "    trace2       = go.Bar(x= (show_metrics[0].values),\n",
    "                          y= [Accuracy, Precision, Recall, F1_score], text= np.round_(show_metrics[0].values, 4),\n",
    "                              textposition = 'auto',\n",
    "                              orientation  = 'h'   , opacity= 0.8,\n",
    "                              marker       = dict(color = colors ,\n",
    "                              line         = dict(color= '#000000', width= 1.5)))\n",
    "    model = model                 #Plots\n",
    "    fig   = plotly.subplots.make_subplots(rows=2, cols=1, print_grid= False,\n",
    "                                          subplot_titles= ('Confusion_Matrix', 'Metrics'))\n",
    "    fig.append_trace(trace1, 1, 1)\n",
    "    fig.append_trace(trace2, 2, 1)\n",
    "    fig['layout'].update(showlegend    = False, title= '<b>Model performance report</b><br>' + str(model),\n",
    "                         autosize      = True, height= 800, width= 800,\n",
    "                         plot_bgcolor  = 'rgba(240, 240, 240, 0.95)',\n",
    "                         paper_bgcolor = 'rgba(240, 240, 240, 0.95)',\n",
    "                        )\n",
    "    fig.layout.titlefont.size = 14\n",
    "    py.offline.iplot(fig)\n",
    "    fig.show(renderer= \"browser\")\n",
    "extree = ExtraTreesClassifier()\n",
    "extree.fit(X_train, Y_train)\n",
    "Y_pred = extree.predict(X_test)\n",
    "print (\"Hyper parameters | input options: \\n\", extree.get_params())\n",
    "model_performance(extree, Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HYPER PARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gkf = KFold(n_splits= 3, shuffle= True, random_state= 42).split(X= X_train, y= Y_train)\n",
    "                                  #Parameter grid of ETrees\n",
    "params = {\n",
    "    'n_estimators'      : range(100, 500, 100),\n",
    "    'ccp_alpha'         : [0.0, 0.1],\n",
    "    'criterion'         : ['gini'],\n",
    "    'max_depth'         : [5,11],\n",
    "    'min_samples_split' : [2,3],\n",
    "         }\n",
    "extree_estimator = ExtraTreesClassifier()\n",
    "g_search = GridSearchCV(\n",
    "                         estimator = extree_estimator,\n",
    "                        param_grid = params,\n",
    "                           scoring = 'f1_weighted',\n",
    "                            n_jobs = 1,\n",
    "                                cv = gkf,\n",
    "                           verbose = 3,\n",
    "                       )\n",
    "extree_model = g_search.fit(X= X_train, y= Y_train)\n",
    "print (\"Best Score post tuning: \\n\", g_search.best_params_, g_search.best_score_)\n",
    "\n",
    "extree_tuned = ExtraTreesClassifier(\n",
    "                                    ccp_alpha          = 0.0,\n",
    "                                    criterion          = 'gini',\n",
    "                                    min_samples_split  = 2,\n",
    "                                    class_weight       = 'balanced',\n",
    "                                    max_depth          = 15,\n",
    "                                    n_estimators       = 400\n",
    "                                   )\n",
    "extree_tuned.fit(X_train, Y_train)\n",
    "Y_pred_tuned = extree_tuned.predict(X_test)\n",
    "print(\"Final tuned throughput: \\n\", Y_pred_tuned)\n",
    "print(np.concatenate((Y_pred_tuned.reshape(len(Y_pred_tuned),1), Y_test.reshape(len(Y_test),1)),1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLAINABLE - AI [SHAP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.initjs()\n",
    "X_sample = X_train.sample(500)\n",
    "print (\"Sample taking for shap value calculation\\n\", X_sample)\n",
    "shap_values = shap.TreeExplainer(extree_tuned).shap_values(X_sample)\n",
    "print (\"Printing the shap values of identified sample\\n\", shap_values)\n",
    "print (\"Shap Summary Plot : Below\\n\")\n",
    "shap.summary_plot(shap_values, X_sample, plot_type=\"bar\")\n",
    "shap.summary_plot(shap_values, X_sample, max_display=28)\n",
    "shap.force_plot(shap.TreeExplainer(extree_tuned).expected_value[0],\n",
    "                shap_values[0][:],\n",
    "                X_sample)\n",
    "print (Y_pred_tuned[50])\n",
    "shap.force_plot(shap.TreeExplainer(extree_tuned).expected_value[0], \n",
    "                                   shap_values[1][50], \n",
    "                                   X_sample.iloc[50])\n",
    "i=13\n",
    "print (Y_pred_tuned[i])\n",
    "shap.force_plot(shap.TreeExplainer(extree_tuned).expected_value[0], \n",
    "                                   shap_values[0][i], \n",
    "                                   X_sample.values[i], \n",
    "                                   feature_names = X_sample.columns)\n",
    "print (Y_pred_tuned[10])\n",
    "row = 10\n",
    "shap.waterfall_plot(shap.Explanation(values=shap_values[0][row],\n",
    "                                     base_values=shap.TreeExplainer(extree_tuned).expected_value[0], \n",
    "                                     data=X_sample.iloc[row],\n",
    "                                     feature_names=X_sample.columns.tolist()))\n",
    "shap.dependence_plot('Day_of_week', shap_values[2], X_sample)\n",
    "shap.dependence_plot('Age_band_of_driver', shap_values[2], X_sample)\n",
    "print(Y_pred_tuned[10])\n",
    "shap.decision_plot(shap.TreeExplainer(extree_tuned).expected_value[0],\n",
    "                   shap_values[2][:10],\n",
    "                   feature_names=X_sample.columns.tolist())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
